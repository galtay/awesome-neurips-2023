{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of NeurIPS 2023 Accepted Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc_file('matplotlibrc')\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/neurips2022data.json\", \"r\") as f:\n",
    "    neurips_2022_data = json.load(f)\n",
    "\n",
    "with open(\"data/neurips2023data.json\", \"r\") as f:\n",
    "    neurips_2023_data = json.load(f)\n",
    "\n",
    "with open(\"data/stopwords.txt\", \"r\") as f:\n",
    "    stopwords = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_2022 = [d.lower() for d in neurips_2022_data.keys()]\n",
    "titles_2023 = [d.lower() for d in neurips_2023_data.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(titles, stopwords, filename):\n",
    "    title_text = ' '.join(titles)\n",
    "    title_text = ' '.join([word for word in title_text.split() if word not in stopwords])\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        max_font_size=100, \n",
    "        min_font_size = 10, \n",
    "        max_words=100, \n",
    "        background_color=\"white\", \n",
    "        width = 533*2, \n",
    "        height = 253*2, \n",
    "        mode=\"RGBA\"\n",
    "        ).generate(title_text)\n",
    "    wordcloud.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, titles in zip([\"2022\", \"2023\"], [titles_2022, titles_2023]):\n",
    "    generate_wordcloud(titles, stopwords, f\"images/wordcloud_{year}.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023 Title Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Neurips 2023 Title Wordcloud](images/wordcloud_2023.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(neurips_2023_data.keys())\n",
    "\n",
    "abstracts = [neurips_2023_data[key][\"abstract\"] for key in keys]\n",
    "abstracts = [abstract.lower() for abstract in abstracts if abstract!=\"\"]\n",
    "abstract_lengths = [len(abstract.split()) for abstract in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(abstract_lengths, bins=100, density=True);\n",
    "plt.xlabel(\"Abstract Length (words)\");\n",
    "plt.ylabel(\"Density\");\n",
    "plt.title(\"Abstract Lengths for NeurIPS 2023 Papers\");\n",
    "plt.savefig(\"images/abstract_histogram_2023.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_abstracts = sorted(zip(abstract_lengths, abstracts), key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longest abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_abstracts[0][1])\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(f\"Num words {len(sorted_abstracts[0][1].split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ From \"[Re] On the Reproducibility of \\u201cFairCal: Fairness Calibration for Face Verification\\u201d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortest abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_abstracts[-1][1])\n",
    "\n",
    "print(f\"Num words {len(sorted_abstracts[-1][1].split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ This is a spotlight poster: \"Improved Convergence in High Probability of Clipped Gradient Methods with Heavy Tailed Noise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_authors_2022 = [\n",
    "    len(v) for v in neurips_2022_data.values()\n",
    "]\n",
    "\n",
    "num_authors_2023 = [\n",
    "    len(neurips_2023_data[k]['authors']) for k in keys\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "author_counts_2022 = Counter(num_authors_2022)\n",
    "author_counts_2023 = Counter(num_authors_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = sorted(set(author_counts_2022.keys()).union(set(author_counts_2023.keys())))\n",
    "values_2022 = [author_counts_2022.get(k, 0) for k in all_keys]\n",
    "values_2023 = [author_counts_2023.get(k, 0) for k in all_keys]\n",
    "\n",
    "# Set up the bar width and positions\n",
    "bar_width = 0.35\n",
    "r1 = range(len(all_keys))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(r1, values_2022, color='blue', width=bar_width, edgecolor='grey', label='2022')\n",
    "plt.bar(r2, values_2023, color='red', width=bar_width, edgecolor='grey', label='2023')\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Authors')\n",
    "plt.ylabel('Number of Papers')\n",
    "plt.title('Comparison of Number of Authors per Paper for 2022 vs 2023')\n",
    "plt.xticks([r + bar_width / 2 for r in r1], all_keys);\n",
    "\n",
    "# Add a legend\n",
    "plt.legend();\n",
    "plt.savefig(\"images/num_authors_2022_2023.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently there were some papers in 2023 with 1 author, when there were none in 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Number of Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_authors_2022 = np.mean(num_authors_2022)\n",
    "mean_authors_2023 = np.mean(num_authors_2023)\n",
    "\n",
    "print(f\"Mean number of authors per paper in 2022: {mean_authors_2022}\")\n",
    "print(f\"Mean number of authors per paper in 2023: {mean_authors_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the single author papers, the mean number of authors in 2023 is still higher than in 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper with the Most Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurips_2023_data[keys[int(np.argmax(num_authors_2023))]][\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Prolific Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: This assumes that the author names are consistent across papers, and that the author names are unique, which is not always the case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_authors_2022 = set()\n",
    "for v in neurips_2022_data.values():\n",
    "    unique_authors_2022.update(v)\n",
    "\n",
    "unique_authors_2023 = set()\n",
    "for v in neurips_2023_data.values():\n",
    "    unique_authors_2023.update(v[\"authors\"])\n",
    "\n",
    "print(f\"Number of unique authors in 2022: {len(unique_authors_2022)}\")\n",
    "print(f\"Number of unique authors in 2023: {len(unique_authors_2023)}\")\n",
    "\n",
    "authors_counts = {\n",
    "    author_name: 0 for author_name in unique_authors_2023\n",
    "}\n",
    "\n",
    "for v in neurips_2023_data.values():\n",
    "    for author in v[\"authors\"]:\n",
    "        authors_counts[author] += 1\n",
    "\n",
    "authors_counts = sorted(authors_counts.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most prolific authors in 2023:\")\n",
    "print(\"-----------------------------\")\n",
    "for author, count in authors_counts[:10]:\n",
    "    print(f\"{author}: {count} papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title Length Comparison between 2022 and 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_lengths_2022 = [len(title.split()) for title in titles_2022]\n",
    "title_lengths2023 = [len(neurips_2023_data[key][\"title\"].split()) for key in keys]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(title_lengths_2022, bins=100, density=True, label=\"2022\");\n",
    "plt.hist(title_lengths2023, bins=100, density=True, label=\"2023\");\n",
    "plt.xlabel(\"Title Length (words)\");\n",
    "plt.ylabel(\"Density\");\n",
    "plt.legend();\n",
    "plt.savefig(\"images/title_length_histogram_2022_2023.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_title_length_2022 = np.mean(title_lengths_2022)\n",
    "mean_title_length_2023 = np.mean(title_lengths2023)\n",
    "\n",
    "print(f\"Mean title length in 2022: {mean_title_length_2022}\")\n",
    "print(f\"Mean title length in 2023: {mean_title_length_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles are trending longer in 2023!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _introduces_acronym(title):\n",
    "    return \":\" in title and len(title.split(\":\")[0].split(\"(\")[0].split()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_acronyms_2022 = sum([_introduces_acronym(title) for title in titles_2022])\n",
    "num_acronyms_2023 = sum([_introduces_acronym(neurips_2023_data[key][\"title\"]) for key in keys])\n",
    "\n",
    "percentage_acronyms_2022 = num_acronyms_2022 / len(titles_2022)\n",
    "percentage_acronyms_2023 = num_acronyms_2023 / len(keys)\n",
    "\n",
    "print(f\"Percentage of titles that introduce acronyms in 2022: {percentage_acronyms_2022}\")\n",
    "print(f\"Percentage of titles that introduce acronyms in 2023: {percentage_acronyms_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the acronyms per paper are trending up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles with LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_titles_with_latex_2022 = sum([\"$\" in title for title in titles_2022])\n",
    "num_titles_with_latex_2023 = sum([\"$\" in neurips_2023_data[key][\"title\"] for key in keys])\n",
    "\n",
    "percentage_titles_with_latex_2022 = num_titles_with_latex_2022 / len(titles_2022)\n",
    "percentage_titles_with_latex_2023 = num_titles_with_latex_2023 / len(keys)\n",
    "\n",
    "print(f\"Percentage of titles that contain LaTeX in 2022: {percentage_titles_with_latex_2022}\")\n",
    "print(f\"Percentage of titles that contain LaTeX in 2023: {percentage_titles_with_latex_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas no titles had LaTeX in 2022, about 1% of titles in 2023 have LaTeX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Analysis of Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [neurips_2023_data[key][\"abstract\"].lower() for key in keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mentions of GitHub, Project Page, or License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abstracts that mention GitHub\n",
    "num_with_github = sum([\"github\" in abs for abs in abstracts])\n",
    "\n",
    "## Abstracts with a link that isn't GitHub\n",
    "def _has_url(text):\n",
    "    patts = [\"http\", \"www\", \".com\", \".edu\", \".gov\"]\n",
    "    return any([patt in text for patt in patts])\n",
    "\n",
    "num_with_site = sum([(\"github\" not in abs and _has_url(abs)) for abs in abstracts])\n",
    "\n",
    "def _has_hf(text):\n",
    "    patts = [\"hugging face\", \"huggingface\"]\n",
    "    return any([patt in text for patt in patts])\n",
    "\n",
    "num_with_hf = sum([(_has_hf(abs)) for abs in abstracts])\n",
    "num_with_license = sum([\"license\" in abs for abs in abstracts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub: 671\n",
      "Project Site: 79\n",
      "Hugging Face: 9\n",
      "License: 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"GitHub: {num_with_github}\")\n",
    "print(f\"Project Site: {num_with_site}\")\n",
    "print(f\"Hugging Face: {num_with_hf}\")\n",
    "print(f\"License: {num_with_license}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurrences of ML Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _count_occurrences_of_words(abstracts, words):\n",
    "    '''\n",
    "    Counts the number of abstracts that contain at least one \n",
    "    of the words in the list of words.\n",
    "    '''\n",
    "    i = 0\n",
    "    for abstract in abstracts:\n",
    "        for word in words:\n",
    "            if word in abstract:\n",
    "                i += 1\n",
    "                break\n",
    "    return i\n",
    "\n",
    "def _print_occurrences_of_words(abstracts, words):\n",
    "    '''\n",
    "    Prints the number of abstracts that contain at least one \n",
    "    of the words in the list of words.\n",
    "    '''\n",
    "    num_occurrences_2023 = _count_occurrences_of_words(abstracts, words)\n",
    "    print(f\"# occurrences of {words[0]} words: {num_occurrences_2023}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BROAD_STROKES_KEYWORDS = (\n",
    "    [\"sampling\"],\n",
    "    [\"differentiable\", \"differentiation\"],\n",
    "    [\"model\"],\n",
    "    [\"data\"],\n",
    "    [\"benchmark\"],\n",
    "    [\"representation\"],\n",
    "    [\"robust\", \"robustness\", \"robustly\"],\n",
    "    [\"learning\", \"learn\"],\n",
    "    [\"foundation\"],\n",
    ")\n",
    "\n",
    "MODALITY_KEYWORDS = (\n",
    "    [\"vision\", \"visual\"],\n",
    "    [\"language\"],\n",
    "    [\"audio\"],\n",
    "    [\"text\"],\n",
    "    [\"video\"],\n",
    "    [\"speech\"],\n",
    "    [\"time series\", \"time-series\", \"temporal\"],\n",
    "    [\"multi-modal\", \"multimodal\"],\n",
    "    [\"cross-modal\", \"crossmodal\"],\n",
    ")\n",
    "\n",
    "TASK_KEYWORDS = (\n",
    "    [\"classification\", \"classify\"],\n",
    "    [\"regression\", \"regress\"],\n",
    "    [\"generation\", \"generate\"],\n",
    "    [\"translation\", \"translate\"],\n",
    "    [\"segmentation\", \"segment\"],\n",
    "    [\"detection\", \"detect\"],\n",
    "    [\"localization\", \"localize\"],\n",
    "    [\"reconstruction\", \"reconstruct\"],\n",
    "    [\"representation\", \"represent\"],\n",
    "    [\"embedding\", \"embed\"],\n",
    "    [\"prediction\", \"predict\"],\n",
    "    [\"synthesis\", \"synthesize\"],\n",
    "    [\"imitation\", \"imitate\"],\n",
    "    [\"plan\"],\n",
    "    [\"control\"],\n",
    "    [\"search\"],\n",
    "    [\"optimization\", \"optimize\"],\n",
    "    [\"adversarial\", \"adversary\", \"adversaries\"],\n",
    "    [\"generative\", \"generation\"],\n",
    "    [\"privacy\", \"private\"],\n",
    "    [\"distill\"],\n",
    "    [\"federated\"],\n",
    "    [\"adapt\"],\n",
    "    [\"transfer\"],\n",
    "    [\"meta\"],\n",
    "    [\"few-shot\", \"few shot\"],\n",
    "    [\"zero-shot\", \"zero shot\"],\n",
    "    [\"fine-tuning\", \"finetuning\"],\n",
    "    [\"reinforcement learning\", \" rl \", \"(rl)\"],\n",
    "    [\"multi-task\", \"multitask\"],\n",
    ")\n",
    "\n",
    "THEORY_KEYWORDS = (\n",
    "    [\"bayes\"],\n",
    "    [\"monte-carlo\", \"monte carlo\"],\n",
    "    [\"gauss\"],\n",
    "    [\"efficient\", \"efficiency\"],\n",
    "    [\"supervised\", \"supervision\"],\n",
    ")\n",
    "\n",
    "MODEL_KEYWORDS = (\n",
    "    [\"clip\", \"contrastive language-image pre-training\"],\n",
    "    [\"nerf\", \"neural radiance fields\"],\n",
    "    [\"transformer\"],\n",
    "    [\"llm\", \"large language model\"],\n",
    "    [\"gpt\"],\n",
    "    [\"gnn\", \"graph neural network\"],\n",
    "    [\"agent\"]\n",
    ")\n",
    "\n",
    "LANGUAGE_KEYWORDS = [\n",
    "    [\"open\"],\n",
    "    [\"vocabulary\"],\n",
    "    [\"prompt\"],\n",
    "    [\"grounding\", \"grounded\"],\n",
    "]\n",
    "\n",
    "DIMENSION_KEYWORDS = [\n",
    "    [\"2d\"],\n",
    "    [\"3d\"],\n",
    "    [\"4d\"],\n",
    "    [\"6d\"],\n",
    "]\n",
    "\n",
    "MULTIMODAL_KEYWORDS = [\n",
    "    [\"vision-language\", \"vision language\"],\n",
    "    [\"text-to-image\", \"text to image\", \"t2i\"],\n",
    "    [\"image-to-text\", \"image to text\", \"i2t\"],\n",
    "    [\"text-to-video\", \"text to video\", \"t2v\"],\n",
    "    [\"captioning\"],\n",
    "    [\"visual question answering\", \"vqa\"],\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broad Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------BROAD STROKES--------\n",
      "# occurrences of sampling words: 319\n",
      "# occurrences of differentiable words: 80\n",
      "# occurrences of model words: 2361\n",
      "# occurrences of data words: 2134\n",
      "# occurrences of benchmark words: 731\n",
      "# occurrences of representation words: 593\n",
      "# occurrences of robust words: 512\n",
      "# occurrences of learning words: 2198\n",
      "# occurrences of foundation words: 111\n"
     ]
    }
   ],
   "source": [
    "print(\"--------BROAD STROKES--------\")\n",
    "for words in BROAD_STROKES_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------MODALITY--------\n",
      "# occurrences of vision words: 614\n",
      "# occurrences of language words: 556\n",
      "# occurrences of audio words: 47\n",
      "# occurrences of text words: 804\n",
      "# occurrences of video words: 180\n",
      "# occurrences of speech words: 33\n",
      "# occurrences of time series words: 258\n",
      "# occurrences of multi-modal words: 156\n",
      "# occurrences of cross-modal words: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"--------MODALITY--------\")\n",
    "for words in MODALITY_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------TASK--------\n",
      "# occurrences of classification words: 389\n",
      "# occurrences of regression words: 226\n",
      "# occurrences of generation words: 677\n",
      "# occurrences of translation words: 83\n",
      "# occurrences of segmentation words: 156\n",
      "# occurrences of detection words: 260\n",
      "# occurrences of localization words: 55\n",
      "# occurrences of reconstruction words: 165\n",
      "# occurrences of representation words: 813\n",
      "# occurrences of embedding words: 217\n",
      "# occurrences of prediction words: 725\n",
      "# occurrences of synthesis words: 117\n",
      "# occurrences of imitation words: 319\n",
      "# occurrences of plan words: 227\n",
      "# occurrences of control words: 301\n",
      "# occurrences of search words: 593\n",
      "# occurrences of optimization words: 652\n",
      "# occurrences of adversarial words: 243\n",
      "# occurrences of generative words: 506\n",
      "# occurrences of privacy words: 158\n",
      "# occurrences of distill words: 100\n",
      "# occurrences of federated words: 76\n",
      "# occurrences of adapt words: 490\n",
      "# occurrences of transfer words: 209\n",
      "# occurrences of meta words: 116\n",
      "# occurrences of few-shot words: 77\n",
      "# occurrences of zero-shot words: 134\n",
      "# occurrences of fine-tuning words: 189\n",
      "# occurrences of reinforcement learning words: 357\n",
      "# occurrences of multi-task words: 63\n"
     ]
    }
   ],
   "source": [
    "print(\"--------TASK--------\")\n",
    "for words in TASK_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------THEORY--------\n",
      "# occurrences of bayes words: 174\n",
      "# occurrences of monte-carlo words: 56\n",
      "# occurrences of gauss words: 195\n",
      "# occurrences of efficient words: 961\n",
      "# occurrences of supervised words: 425\n"
     ]
    }
   ],
   "source": [
    "print(\"--------THEORY--------\")\n",
    "for words in THEORY_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------MODEL--------\n",
      "# occurrences of clip words: 118\n",
      "# occurrences of nerf words: 34\n",
      "# occurrences of transformer words: 270\n",
      "# occurrences of llm words: 237\n",
      "# occurrences of gpt words: 113\n",
      "# occurrences of gnn words: 133\n",
      "# occurrences of agent words: 279\n"
     ]
    }
   ],
   "source": [
    "print(\"--------MODEL--------\")\n",
    "for words in MODEL_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------LANGUAGE--------\n",
      "# occurrences of open words: 352\n",
      "# occurrences of vocabulary words: 38\n",
      "# occurrences of prompt words: 198\n",
      "# occurrences of grounding words: 55\n"
     ]
    }
   ],
   "source": [
    "print(\"--------LANGUAGE--------\")\n",
    "for words in LANGUAGE_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------DIMENSION--------\n",
      "# occurrences of 2d words: 87\n",
      "# occurrences of 3d words: 212\n",
      "# occurrences of 4d words: 17\n",
      "# occurrences of 6d words: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"--------DIMENSION--------\")\n",
    "for words in DIMENSION_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------MULTIMODAL--------\n",
      "# occurrences of vision-language words: 76\n",
      "# occurrences of text-to-image words: 74\n",
      "# occurrences of image-to-text words: 6\n",
      "# occurrences of text-to-video words: 3\n",
      "# occurrences of captioning words: 27\n",
      "# occurrences of visual question answering words: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"--------MULTIMODAL--------\")\n",
    "for words in MULTIMODAL_KEYWORDS:\n",
    "    _print_occurrences_of_words(abstracts, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Modality Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, _ = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"vision\", \"text\", \"audio\", \"tabular\", \"time series\", \"multimodal\"]\n",
    "labels = [f\"Abstract of a machine learning paper about {c} models and data\" for c in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3581, 6])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_categories = clip.tokenize(labels).to(device)\n",
    "tokenized_abstracts = clip.tokenize(abstracts, truncate=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    category_features = model.encode_text(tokenized_categories)\n",
    "    abstract_features = model.encode_text(tokenized_abstracts)\n",
    "\n",
    "category_features = category_features / category_features.norm(dim=-1, keepdim=True)\n",
    "abstract_features = abstract_features / abstract_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "logits = torch.matmul(abstract_features, category_features.T)\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values, max_indices = torch.max(logits, dim=1)\n",
    "modality_counts = Counter(max_indices.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_modality = {\n",
    "    categories[i]: modality_counts[i]\n",
    "    for i in range(len(categories))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vision': 966,\n",
       " 'text': 657,\n",
       " 'audio': 66,\n",
       " 'tabular': 328,\n",
       " 'time series': 269,\n",
       " 'multimodal': 1295}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fo-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
